{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q3 Using Scikit-Learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "import gc\n",
    "\n",
    "from sklearn.model_selection import cross_val_score, GridSearchCV, cross_validate, train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import StandardScaler, normalize\n",
    "from sklearn.decomposition import PCA\n",
    "# Import statements run before running other code cells"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classifier Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# XXX\n",
    "# TODO: Read in all the data. Replace the 'xxx' with the path to the data set.\n",
    "# XXX\n",
    "\n",
    "# data = pd.read_csv('xxx')\n",
    "\n",
    "# Separate out the x_data and y_data.\n",
    "# x_data = data.loc[:, data.columns != \"y\"]\n",
    "# y_data = data.loc[:, \"y\"]\n",
    "\n",
    "# -------------------------------\n",
    "# ADD CODE HERE\n",
    "data  = pd.read_csv('./pulsar_stars.csv')\n",
    "x_data = data.loc[:, data.columns !='y']\n",
    "y_data = data.loc[:, 'y']\n",
    "#print(x_data)\n",
    "# -------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The random state to use while splitting the data.\n",
    "random_state = 100\n",
    "\n",
    "# XXX\n",
    "# TODO: Split 70% of the data into training and 30% into test sets. Call them x_train, x_test, y_train and y_test.\n",
    "# Use the train_test_split method in sklearn with the parameter 'shuffle' set to true and the 'random_state' set to 100.\n",
    "# XXX\n",
    "\n",
    "# -------------------------------\n",
    "# ADD CODE HERE\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x_data, y_data, test_size=0.30, random_state=random_state, shuffle=True)\n",
    "# -------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Regression "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression(copy_X=True, fit_intercept=True, n_jobs=None, normalize=False)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# XXX\n",
    "# TODO: Create a LinearRegression classifier and train it.\n",
    "# XXX\n",
    "\n",
    "# -------------------------------\n",
    "# ADD CODE HERE\n",
    "lm = LinearRegression()\n",
    "lm.fit(x_train, y_train)\n",
    "# -------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Training Accuracyis: 97.030651\n"
     ]
    }
   ],
   "source": [
    "# XXX\n",
    "# TODO: Test its accuracy (on the training set) using the accuracy_score method.\n",
    "# Note: Round the output values greater than or equal to 0.5 to 1 and those less than 0.5 to 0. You can use y_predict.round() or any other method.\n",
    "# XXX\n",
    "\n",
    "# -------------------------------\n",
    "# ADD CODE HERE\n",
    "y_train_predicted = lm.predict(x_train)\n",
    "train_accuracy = accuracy_score(y_train, y_train_predicted.round(), normalize=True)*100\n",
    "print(\"The Training Accuracyis: %f\" % train_accuracy)\n",
    "# -------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Testing Accuracyis: 97.150838\n"
     ]
    }
   ],
   "source": [
    "# XXX\n",
    "# TODO: Test its accuracy (on the testing set) using the accuracy_score method.\n",
    "# Note: Round the output values greater than or equal to 0.5 to 1 and those less than 0.5 to 0. You can use y_predict.round() or any other method.\n",
    "# XXX\n",
    "\n",
    "# -------------------------------\n",
    "# ADD CODE HERE\n",
    "y_test_predicted = lm.predict(x_test)\n",
    "test_accuracy= accuracy_score(y_test, y_test_predicted.round(), normalize= True)*100\n",
    "print(\"The Testing Accuracyis: %f\" % test_accuracy)\n",
    "\n",
    "# -------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "                       max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, n_estimators=10,\n",
       "                       n_jobs=None, oob_score=False, random_state=100,\n",
       "                       verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# XXX\n",
    "# TODO: Create a RandomForestClassifier and train it.\n",
    "# WARNING: Ignore \"FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\"10 in version 0.20 to 100 in 0.22.\"\n",
    "# XXX\n",
    "\n",
    "# -------------------------------\n",
    "# ADD CODE HERE\n",
    "rf_model =RandomForestClassifier(random_state=random_state)\n",
    "rf_model.fit(x_train, y_train)\n",
    "\n",
    "# -------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Training Accuracy: 0.996089\n"
     ]
    }
   ],
   "source": [
    "# XXX\n",
    "# TODO: Test its accuracy on the training set using the accuracy_score method.\n",
    "# XXX\n",
    "\n",
    "# -------------------------------\n",
    "# ADD CODE HERE\n",
    "y_train_predicted= rf_model.predict(x_train)\n",
    "rf_train_accuracy= accuracy_score(y_train, y_train_predicted.round())\n",
    "print(\"The Training Accuracy: %f\" % rf_train_accuracy)\n",
    "\n",
    "# -------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Training Accuracy: 0.981006\n"
     ]
    }
   ],
   "source": [
    "# XXX\n",
    "# TODO: Test its accuracy on the test set using the accuracy_score method.\n",
    "# XXX\n",
    "\n",
    "# -------------------------------\n",
    "# ADD CODE HERE\n",
    "y_test_predicted= rf_model.predict(x_test)\n",
    "rf_test_accuracy= accuracy_score(y_test, y_test_predicted.round())\n",
    "print(\"The Training Accuracy: %f\" % rf_test_accuracy)\n",
    "\n",
    "# -------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.1257031  0.03131994 0.45697513 0.16258565 0.05165992 0.08903044\n",
      " 0.05408017 0.02864564]\n"
     ]
    }
   ],
   "source": [
    "# XXX\n",
    "# TODO: Determine and print the feature importance as evaluated by the Random Forest Classifier.\n",
    "# XXX\n",
    "\n",
    "# -------------------------------\n",
    "# ADD CODE HERE\n",
    "rf_fea_impo= rf_model.feature_importances_\n",
    "print(rf_fea_impo)\n",
    "rf_fea_impo= rf_fea_impo.tolist()\n",
    "# -------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# XXX\n",
    "# TODO: Sort them in the descending order and print the feature numbers[0 to ...].\n",
    "#       Hint: There is a direct function available in sklearn to achieve this. Also checkout argsort() function in Python.\n",
    "# XXX\n",
    "\n",
    "# -------------------------------\n",
    "# ADD CODE HERE\n",
    "\n",
    "new_dict={}\n",
    "for i in rf_fea_impo:\n",
    "    new_dict[rf_fea_impo.index(i)]=i\n",
    "sorted_dict= sorted(new_dict.items(), key=lambda kv:kv[1], reverse= True)\n",
    "#print(sorted_dict)\n",
    "\n",
    "for value in sorted_dict:\n",
    "    print(\"X%d %f\" % (value[0], value[1]))\n",
    "\n",
    "\n",
    "# -------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyper-parameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameter after CV:{'max_depth': 100, 'n_estimators': 40}\n",
      "The socre is: 0.9789272030651341\n"
     ]
    }
   ],
   "source": [
    "# XXX\n",
    "# TODO: Tune the hyper-parameters 'n_estimators' and 'max_depth'.\n",
    "# XXX\n",
    "\n",
    "# -------------------------------\n",
    "# ADD CODE HERE\n",
    "rf_params = {'n_estimators': [ 40 ,60, 80 ], 'max_depth': [50,75 ,100]}\n",
    "tuned_rf = RandomForestClassifier()\n",
    "fixed_model = GridSearchCV(tuned_rf, rf_params, cv=10)\n",
    "fixed_model.fit(x_train, y_train)\n",
    "\n",
    "\n",
    "\n",
    "# -------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameter after CV:{'max_depth': 100, 'n_estimators': 40}\n"
     ]
    }
   ],
   "source": [
    "# XXX\n",
    "# TODO: Print the best params, using .best_params_\n",
    "# XXX\n",
    "\n",
    "# -------------------------------\n",
    "# ADD CODE HERE\n",
    "print(\"Best parameter after CV:\" +str(fixed_model.best_params_))\n",
    "\n",
    "# -------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best socre is: 0.9789272030651341\n"
     ]
    }
   ],
   "source": [
    "# XXX\n",
    "# TODO: Print the best score, using .best_score_.\n",
    "# XXX\n",
    "\n",
    "# -------------------------------\n",
    "# ADD CODE HERE\n",
    "print(\"The best socre is: \" + str(fixed_model.best_score_))\n",
    "# -------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Support Vector Machine"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# XXX\n",
    "# TODO: Pre-process the data to standardize or normalize it, otherwise the grid search will take much longer.\n",
    "# Warning: Ignore \"FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning\"\n",
    "# XXX\n",
    "\n",
    "# -------------------------------\n",
    "# ADD CODE HERE\n",
    "\n",
    "normalized_x_train = normalize(x_train)\n",
    "normalized_x_test = normalize(x_test)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# -------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "    decision_function_shape='ovr', degree=3, gamma='auto', kernel='rbf',\n",
       "    max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "    tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# XXX\n",
    "# TODO: Create a SVC classifier and train it.\n",
    "# XXX\n",
    "\n",
    "# -------------------------------\n",
    "# ADD CODE HERE\n",
    "\n",
    "svc_model = SVC(gamma= 'auto')\n",
    "svc_model.fit(normalized_x_train, y_train)\n",
    "\n",
    "\n",
    "# -------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.966794380587484"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# XXX\n",
    "# TODO: Test its accuracy on the training set using the accuracy_score method.\n",
    "# XXX\n",
    "# WARNING: Ignore \"FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\"\"\n",
    "\n",
    "# -------------------------------\n",
    "# ADD CODE HERE\n",
    "y_train_predicted_svc = svc_model.predict(normalized_x_train)\n",
    "accuracy_score(y_train,y_train_predicted_svc.round())\n",
    "# -------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.970391061452514"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# XXX\n",
    "# TODO: Test its accuracy on the test set using the accuracy_score method.\n",
    "# XXX\n",
    "# WARNING: Ignore \"FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\"\"\n",
    "\n",
    "# -------------------------------\n",
    "# ADD CODE HERE\n",
    "y_test_predicted_svc = svc_model.predict(normalized_x_test)\n",
    "accuracy_score(y_test,y_test_predicted_svc.round())\n",
    "\n",
    "# -------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyper-parameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=10, error_score='raise-deprecating',\n",
       "             estimator=SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "                           decision_function_shape='ovr', degree=3,\n",
       "                           gamma='auto', kernel='rbf', max_iter=-1,\n",
       "                           probability=False, random_state=None, shrinking=True,\n",
       "                           tol=0.001, verbose=False),\n",
       "             iid='warn', n_jobs=None,\n",
       "             param_grid={'C': [0.001, 0.01, 0.1, 1, 10],\n",
       "                         'kernel': ['linear', 'rbf']},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=True,\n",
       "             scoring=None, verbose=0)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# XXX\n",
    "# TODO: Tune the hyper-parameters 'C' and 'kernel' (use rbf and linear).\n",
    "# XXX\n",
    "\n",
    "# -------------------------------\n",
    "# ADD CODE HERE\n",
    "params_svc = {'C': [0.001,0.01, 0.1 ,1, 10], 'kernel': ['linear', 'rbf']}\n",
    "tuned_svc = SVC(gamma='auto')\n",
    "fixed_svc = GridSearchCV(tuned_svc, params_svc, cv = 10, return_train_score=True)\n",
    "fixed_svc.fit(normalized_x_train, y_train)\n",
    "# -------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best parameter is:{'C': 10, 'kernel': 'linear'}\n",
      "The best score is:0.9723818646232439\n"
     ]
    }
   ],
   "source": [
    "# XXX\n",
    "# TODO: Print the best score, using .best_score_.\n",
    "# XXX\n",
    "\n",
    "# -------------------------------\n",
    "# ADD CODE HERE\n",
    "print(\"The best parameter is:\" +str(fixed_svc.best_params_))\n",
    "print(\"The best score is:\" +str(fixed_svc.best_score_))\n",
    "# -------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=10, cache_size=200, class_weight=None, coef0=0.0,\n",
       "    decision_function_shape='ovr', degree=3, gamma='auto', kernel='linear',\n",
       "    max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "    tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# XXX\n",
    "# TODO: Get the training and test set accuracy values after hyperparameter tuning.\n",
    "# XXX\n",
    "\n",
    "# -------------------------------\n",
    "# ADD CODE HERE\n",
    "\n",
    "optimal_c= (fixed_svc.best_params_.get('C'))\n",
    "optimal_kernel= (fixed_svc.best_params_.get('kernel'))\n",
    "tuned_svc_model = SVC(gamma='auto',C=optimal_c,kernel=optimal_kernel)\n",
    "tuned_svc_model.fit(x_train,y_train)\n",
    "\n",
    "# -------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9786079182630907"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# XXX\n",
    "# TODO: Test its accuracy (on the training set) using the accuracy_score method.\n",
    "# Note: Round the output values greater than or equal to 0.5 to 1 and those less than 0.5 to 0. You can use y_predict.round() or any other method.\n",
    "# XXX\n",
    "\n",
    "# -------------------------------\n",
    "# ADD CODE HERE\n",
    "y_pre_train_svc_tun = tuned_svc_model.predict(x_train)\n",
    "accuracy_score(y_train, y_pre_train_svc_tun.round())\n",
    "\n",
    "# -------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9808193668528864"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# XXX\n",
    "# TODO: Test its accuracy (on the testing set) using the accuracy_score method.\n",
    "# Note: Round the output values greater than or equal to 0.5 to 1 and those less than 0.5 to 0. You can use y_predict.round() or any other method.\n",
    "# XXX\n",
    "\n",
    "# -------------------------------\n",
    "# ADD CODE HERE\n",
    "\n",
    "y_pre_test_svc_tun = tuned_svc_model.predict(x_test)\n",
    "accuracy_score(y_test, y_pre_test_svc_tun.round())\n",
    "# -------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# XXX\n",
    "# TODO: Calculate the rank test score, mean testing score and mean fit time for the \n",
    "# best combination of hyperparameter values that you obtained in Q3.2. The GridSearchCV \n",
    "# class holds a  ‘cv_results_’ dictionary that should help you report these metrics easily.\n",
    "# XXX\n",
    "\n",
    "# -------------------------------\n",
    "# ADD CODE HERE\n",
    "rank=fixed_svc.cv_results_['rank_test_score']\n",
    "mean_test=fixed_svc.cv_results_['mean_test_score']\n",
    "mean_fit=fixed_svc.cv_results_['mean_fit_time']\n",
    "# -------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[8 8 7 8 5 6 3 4 1 2]\n"
     ]
    }
   ],
   "source": [
    "# XXX\n",
    "# TODO: Print the rank test score for the best combination of hyperparameter values that you obtained in Q3.2. The \n",
    "# GridSearchCV class holds a  ‘cv_results_’ dictionary that should help you report these metrics easily.\n",
    "# XXX\n",
    "\n",
    "# -------------------------------\n",
    "# ADD CODE HERE\n",
    "print(rank)\n",
    "# -------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.90876437 0.90876437 0.95450192 0.90876437 0.96328225 0.95729566\n",
      " 0.96982759 0.96655492 0.97238186 0.97126437]\n"
     ]
    }
   ],
   "source": [
    "# XXX\n",
    "# TODO: Print mean testing score for the best combination of hyperparameter values that you obtained in Q3.2. The \n",
    "# GridSearchCV class holds a  ‘cv_results_’ dictionary that should help you report these metrics easily.\n",
    "# XXX\n",
    "\n",
    "# -------------------------------\n",
    "# ADD CODE HERE\n",
    "print(mean_test)\n",
    "# -------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.36521749 0.62163484 0.34014158 0.61939735 0.21794596 0.51500282\n",
      " 0.17683642 0.32872231 0.16120632 0.27285986]\n"
     ]
    }
   ],
   "source": [
    "# XXX\n",
    "# TODO: Print mean fit time for the best combination of hyperparameter values that you obtained in Q3.2. The \n",
    "# GridSearchCV class holds a  ‘cv_results_’ dictionary that should help you report these metrics easily.\n",
    "# XXX\n",
    "\n",
    "# -------------------------------\n",
    "# ADD CODE HERE\n",
    "print(mean_fit)\n",
    "# -------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PCA(copy=True, iterated_power='auto', n_components=8, random_state=None,\n",
       "    svd_solver='full', tol=0.0, whiten=False)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# XXX\n",
    "# TODO: Perform dimensionality reduction of the data using PCA.\n",
    "#       Set parameters n_component to 8 and svd_solver to 'full'. Keep other parameters at their default value.\n",
    "# XXX\n",
    "\n",
    "# -------------------------------\n",
    "# ADD CODE HERE\n",
    "pca = PCA(n_components =8, svd_solver = 'full')\n",
    "pca.fit(x_train)\n",
    "\n",
    "# -------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[8.71054855e-01 7.80404050e-02 4.12747422e-02 6.15520409e-03\n",
      " 2.45425694e-03 9.78533643e-04 3.91429289e-05 2.85984066e-06]\n"
     ]
    }
   ],
   "source": [
    "# XXX\n",
    "# TODO: Print Percentage of variance explained by each of the selected components\n",
    "# XXX\n",
    "\n",
    "# -------------------------------\n",
    "# ADD CODE HERE\n",
    "print(pca.explained_variance_ratio_)\n",
    "# -------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11992.97512747  3589.74779466  2610.63625426  1008.15059028\n",
      "   636.59642313   401.9685368     80.39533321    21.73076915]\n"
     ]
    }
   ],
   "source": [
    "# XXX\n",
    "# TODO: The singular values corresponding to each of the selected components.\n",
    "# XXX\n",
    "\n",
    "# -------------------------------\n",
    "# ADD CODE HERE\n",
    "print(pca.singular_values_)\n",
    "# -------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
